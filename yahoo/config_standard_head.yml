
dataset:
  data: yahoo
    
adapter:
  model:
    roberta-large: "roberta-large"
    roberta: "roberta-base"
  arch:
    - lora
    - ia3
    - pfeiffer
  c_rate: 16
  r: 8
  alpha: 16
  learning_rate: 5.0e-5
  max_epochs: 30
  number_of_runs: 5
  per_device_train_batch_size: 2
  save: False
  